{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "0. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\fabdelli\\python\\lib\\site-packages (0.8.11)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\fabdelli\\python\\lib\\site-packages (4.6.0.66)\n",
      "Requirement already satisfied: pandas in c:\\users\\fabdelli\\python\\lib\\site-packages (1.4.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\fabdelli\\python\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in c:\\users\\fabdelli\\python\\lib\\site-packages (from mediapipe) (3.20.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\fabdelli\\python\\lib\\site-packages (from mediapipe) (1.23.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\fabdelli\\python\\lib\\site-packages (from mediapipe) (3.5.2)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\fabdelli\\python\\lib\\site-packages (from mediapipe) (4.6.0.66)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\fabdelli\\python\\lib\\site-packages (from mediapipe) (21.4.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\fabdelli\\python\\lib\\site-packages (from mediapipe) (1.2.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\fabdelli\\python\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\fabdelli\\python\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\fabdelli\\python\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\fabdelli\\python\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\fabdelli\\python\\lib\\site-packages (from scikit-learn) (1.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\fabdelli\\python\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\fabdelli\\python\\lib\\site-packages (from matplotlib->mediapipe) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\fabdelli\\python\\lib\\site-packages (from matplotlib->mediapipe) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\fabdelli\\python\\lib\\site-packages (from matplotlib->mediapipe) (4.34.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\fabdelli\\python\\lib\\site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\fabdelli\\python\\lib\\site-packages (from matplotlib->mediapipe) (1.4.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\fabdelli\\python\\lib\\site-packages (from matplotlib->mediapipe) (9.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\fabdelli\\python\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\fabdelli\\python\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\fabdelli\\python\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\fabdelli\\python\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\fabdelli\\python\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\fabdelli\\python\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe opencv-python pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp # Import mediapipe\n",
    "import cv2 # Import opencv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils # Drawing helpers\n",
    "mp_holistic = mp.solutions.holistic # Mediapipe Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Make Some Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False        \n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "        # print(results.face_landmarks)\n",
    "        \n",
    "        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True   \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # 1. Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                                 )\n",
    "        \n",
    "        # 2. Right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 3. Left Hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 4. Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "                        \n",
    "        cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.face_landmarks.landmark[0].visibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. Capture Landmarks & Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_coords = len(results.pose_landmarks.landmark)+len(results.face_landmarks.landmark)\n",
    "num_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = ['class']\n",
    "for val in range(1, num_coords+1):\n",
    "    landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('coords.csv', mode='w', newline='') as f:\n",
    "    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = \"Greetings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False        \n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "        # print(results.face_landmarks)\n",
    "        \n",
    "        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True   \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # 1. Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                                 )\n",
    "        \n",
    "        # 2. Right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 3. Left Hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 4. Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        # Export coordinates\n",
    "        try:\n",
    "            # Extract Pose landmarks\n",
    "            pose = results.pose_landmarks.landmark\n",
    "            pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "            \n",
    "            # Extract Face landmarks\n",
    "            face = results.face_landmarks.landmark\n",
    "            face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n",
    "            \n",
    "            # Concate rows\n",
    "            row = pose_row+face_row\n",
    "            \n",
    "            # Append class name \n",
    "            row.insert(0, class_name)\n",
    "            \n",
    "            # Export to CSV\n",
    "            with open('coords.csv', mode='a', newline='') as f:\n",
    "                csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                csv_writer.writerow(row) \n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "                        \n",
    "        cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "3. Train Custom Model Using Scikit Learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Read in Collected Data and Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('coords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>v1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>v2</th>\n",
       "      <th>x3</th>\n",
       "      <th>...</th>\n",
       "      <th>z499</th>\n",
       "      <th>v499</th>\n",
       "      <th>x500</th>\n",
       "      <th>y500</th>\n",
       "      <th>z500</th>\n",
       "      <th>v500</th>\n",
       "      <th>x501</th>\n",
       "      <th>y501</th>\n",
       "      <th>z501</th>\n",
       "      <th>v501</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sad</td>\n",
       "      <td>0.515912</td>\n",
       "      <td>0.327699</td>\n",
       "      <td>-1.180751</td>\n",
       "      <td>0.999871</td>\n",
       "      <td>0.547356</td>\n",
       "      <td>0.271942</td>\n",
       "      <td>-1.144316</td>\n",
       "      <td>0.999882</td>\n",
       "      <td>0.565439</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.582452</td>\n",
       "      <td>0.284713</td>\n",
       "      <td>0.001509</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.588377</td>\n",
       "      <td>0.276495</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sad</td>\n",
       "      <td>0.513921</td>\n",
       "      <td>0.333449</td>\n",
       "      <td>-1.135985</td>\n",
       "      <td>0.999858</td>\n",
       "      <td>0.545993</td>\n",
       "      <td>0.274086</td>\n",
       "      <td>-1.101505</td>\n",
       "      <td>0.999869</td>\n",
       "      <td>0.565188</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.580053</td>\n",
       "      <td>0.280911</td>\n",
       "      <td>0.003963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585523</td>\n",
       "      <td>0.275561</td>\n",
       "      <td>0.003669</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sad</td>\n",
       "      <td>0.512179</td>\n",
       "      <td>0.336637</td>\n",
       "      <td>-1.110512</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.544572</td>\n",
       "      <td>0.275316</td>\n",
       "      <td>-1.076720</td>\n",
       "      <td>0.999864</td>\n",
       "      <td>0.564706</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.579401</td>\n",
       "      <td>0.279346</td>\n",
       "      <td>0.002967</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.584722</td>\n",
       "      <td>0.274277</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sad</td>\n",
       "      <td>0.510677</td>\n",
       "      <td>0.338504</td>\n",
       "      <td>-1.168302</td>\n",
       "      <td>0.999836</td>\n",
       "      <td>0.543580</td>\n",
       "      <td>0.276034</td>\n",
       "      <td>-1.132628</td>\n",
       "      <td>0.999851</td>\n",
       "      <td>0.564398</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.579564</td>\n",
       "      <td>0.278963</td>\n",
       "      <td>0.002561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.584818</td>\n",
       "      <td>0.274160</td>\n",
       "      <td>0.002191</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sad</td>\n",
       "      <td>0.510086</td>\n",
       "      <td>0.339934</td>\n",
       "      <td>-1.126713</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.543109</td>\n",
       "      <td>0.276495</td>\n",
       "      <td>-1.093187</td>\n",
       "      <td>0.999853</td>\n",
       "      <td>0.564265</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.579565</td>\n",
       "      <td>0.277974</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.584708</td>\n",
       "      <td>0.273275</td>\n",
       "      <td>0.002548</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Sad</td>\n",
       "      <td>0.536477</td>\n",
       "      <td>0.362120</td>\n",
       "      <td>-0.715767</td>\n",
       "      <td>0.999219</td>\n",
       "      <td>0.559647</td>\n",
       "      <td>0.312436</td>\n",
       "      <td>-0.682964</td>\n",
       "      <td>0.998836</td>\n",
       "      <td>0.576781</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009472</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.591363</td>\n",
       "      <td>0.310241</td>\n",
       "      <td>-0.000145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.595322</td>\n",
       "      <td>0.304981</td>\n",
       "      <td>-0.000559</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Sad</td>\n",
       "      <td>0.536937</td>\n",
       "      <td>0.362239</td>\n",
       "      <td>-0.726643</td>\n",
       "      <td>0.999170</td>\n",
       "      <td>0.560062</td>\n",
       "      <td>0.312483</td>\n",
       "      <td>-0.696538</td>\n",
       "      <td>0.998757</td>\n",
       "      <td>0.577196</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.591172</td>\n",
       "      <td>0.310362</td>\n",
       "      <td>-0.000087</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.595128</td>\n",
       "      <td>0.305064</td>\n",
       "      <td>-0.000515</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Sad</td>\n",
       "      <td>0.537136</td>\n",
       "      <td>0.362249</td>\n",
       "      <td>-0.701985</td>\n",
       "      <td>0.999181</td>\n",
       "      <td>0.560302</td>\n",
       "      <td>0.312490</td>\n",
       "      <td>-0.674216</td>\n",
       "      <td>0.998771</td>\n",
       "      <td>0.577426</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.591304</td>\n",
       "      <td>0.311462</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.595358</td>\n",
       "      <td>0.305590</td>\n",
       "      <td>-0.000411</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Sad</td>\n",
       "      <td>0.537148</td>\n",
       "      <td>0.362256</td>\n",
       "      <td>-0.706337</td>\n",
       "      <td>0.999152</td>\n",
       "      <td>0.560379</td>\n",
       "      <td>0.312502</td>\n",
       "      <td>-0.677403</td>\n",
       "      <td>0.998732</td>\n",
       "      <td>0.577485</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008691</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.589902</td>\n",
       "      <td>0.313755</td>\n",
       "      <td>-0.000270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.593994</td>\n",
       "      <td>0.307157</td>\n",
       "      <td>-0.000543</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Sad</td>\n",
       "      <td>0.537221</td>\n",
       "      <td>0.362263</td>\n",
       "      <td>-0.703137</td>\n",
       "      <td>0.999147</td>\n",
       "      <td>0.560590</td>\n",
       "      <td>0.312538</td>\n",
       "      <td>-0.673983</td>\n",
       "      <td>0.998722</td>\n",
       "      <td>0.577674</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008560</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.589679</td>\n",
       "      <td>0.314091</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.307552</td>\n",
       "      <td>-0.000273</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157 rows × 2005 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    class        x1        y1        z1        v1        x2        y2  \\\n",
       "0     Sad  0.515912  0.327699 -1.180751  0.999871  0.547356  0.271942   \n",
       "1     Sad  0.513921  0.333449 -1.135985  0.999858  0.545993  0.274086   \n",
       "2     Sad  0.512179  0.336637 -1.110512  0.999852  0.544572  0.275316   \n",
       "3     Sad  0.510677  0.338504 -1.168302  0.999836  0.543580  0.276034   \n",
       "4     Sad  0.510086  0.339934 -1.126713  0.999841  0.543109  0.276495   \n",
       "..    ...       ...       ...       ...       ...       ...       ...   \n",
       "152   Sad  0.536477  0.362120 -0.715767  0.999219  0.559647  0.312436   \n",
       "153   Sad  0.536937  0.362239 -0.726643  0.999170  0.560062  0.312483   \n",
       "154   Sad  0.537136  0.362249 -0.701985  0.999181  0.560302  0.312490   \n",
       "155   Sad  0.537148  0.362256 -0.706337  0.999152  0.560379  0.312502   \n",
       "156   Sad  0.537221  0.362263 -0.703137  0.999147  0.560590  0.312538   \n",
       "\n",
       "           z2        v2        x3  ...      z499  v499      x500      y500  \\\n",
       "0   -1.144316  0.999882  0.565439  ... -0.010937   0.0  0.582452  0.284713   \n",
       "1   -1.101505  0.999869  0.565188  ... -0.010020   0.0  0.580053  0.280911   \n",
       "2   -1.076720  0.999864  0.564706  ... -0.010986   0.0  0.579401  0.279346   \n",
       "3   -1.132628  0.999851  0.564398  ... -0.011556   0.0  0.579564  0.278963   \n",
       "4   -1.093187  0.999853  0.564265  ... -0.011445   0.0  0.579565  0.277974   \n",
       "..        ...       ...       ...  ...       ...   ...       ...       ...   \n",
       "152 -0.682964  0.998836  0.576781  ... -0.009472   0.0  0.591363  0.310241   \n",
       "153 -0.696538  0.998757  0.577196  ... -0.009380   0.0  0.591172  0.310362   \n",
       "154 -0.674216  0.998771  0.577426  ... -0.008988   0.0  0.591304  0.311462   \n",
       "155 -0.677403  0.998732  0.577485  ... -0.008691   0.0  0.589902  0.313755   \n",
       "156 -0.673983  0.998722  0.577674  ... -0.008560   0.0  0.589679  0.314091   \n",
       "\n",
       "         z500  v500      x501      y501      z501  v501  \n",
       "0    0.001509   0.0  0.588377  0.276495  0.001489   0.0  \n",
       "1    0.003963   0.0  0.585523  0.275561  0.003669   0.0  \n",
       "2    0.002967   0.0  0.584722  0.274277  0.002604   0.0  \n",
       "3    0.002561   0.0  0.584818  0.274160  0.002191   0.0  \n",
       "4    0.002918   0.0  0.584708  0.273275  0.002548   0.0  \n",
       "..        ...   ...       ...       ...       ...   ...  \n",
       "152 -0.000145   0.0  0.595322  0.304981 -0.000559   0.0  \n",
       "153 -0.000087   0.0  0.595128  0.305064 -0.000515   0.0  \n",
       "154 -0.000047   0.0  0.595358  0.305590 -0.000411   0.0  \n",
       "155 -0.000270   0.0  0.593994  0.307157 -0.000543   0.0  \n",
       "156 -0.000018   0.0  0.593750  0.307552 -0.000273   0.0  \n",
       "\n",
       "[157 rows x 2005 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['class']==\"Sad\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('class', axis=1) # features\n",
    "y = df['class'] # target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Train Machine Learning Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    'lr':make_pipeline(StandardScaler(), LogisticRegression()),\n",
    "    'rc':make_pipeline(StandardScaler(), RidgeClassifier()),\n",
    "    'rf':make_pipeline(StandardScaler(), RandomForestClassifier()),\n",
    "    'gb':make_pipeline(StandardScaler(), GradientBoostingClassifier()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FABDELLI\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "fit_models = {}\n",
    "for algo, pipeline in pipelines.items():\n",
    "    model = pipeline.fit(X_train, y_train)\n",
    "    fit_models[algo] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sad', 'Greetings', 'Happy', 'Greetings', 'Greetings', 'Greetings',\n",
       "       'Greetings', 'Happy', 'Greetings', 'Greetings', 'Sad', 'Sad',\n",
       "       'Happy', 'Greetings', 'Greetings', 'Happy', 'Greetings', 'Sad',\n",
       "       'Greetings', 'Greetings', 'Greetings', 'Happy', 'Sad', 'Sad',\n",
       "       'Happy', 'Greetings', 'Sad', 'Sad', 'Sad', 'Greetings', 'Happy',\n",
       "       'Sad', 'Greetings', 'Happy', 'Happy', 'Sad', 'Greetings', 'Happy',\n",
       "       'Greetings', 'Sad', 'Sad', 'Sad', 'Sad', 'Greetings', 'Sad',\n",
       "       'Greetings', 'Happy', 'Sad', 'Happy', 'Happy', 'Happy', 'Sad',\n",
       "       'Happy', 'Sad', 'Greetings', 'Happy', 'Greetings', 'Happy',\n",
       "       'Happy', 'Sad', 'Happy', 'Sad', 'Happy', 'Sad', 'Sad', 'Greetings',\n",
       "       'Sad', 'Greetings', 'Greetings', 'Sad', 'Happy', 'Happy', 'Sad',\n",
       "       'Greetings', 'Sad', 'Happy', 'Sad', 'Greetings', 'Happy',\n",
       "       'Greetings', 'Happy', 'Happy', 'Happy', 'Sad', 'Greetings', 'Sad',\n",
       "       'Sad', 'Greetings', 'Greetings', 'Happy', 'Sad', 'Greetings',\n",
       "       'Sad', 'Sad', 'Sad', 'Sad', 'Sad', 'Sad', 'Happy', 'Sad', 'Happy',\n",
       "       'Greetings', 'Greetings', 'Happy', 'Greetings', 'Greetings',\n",
       "       'Greetings', 'Greetings', 'Happy', 'Sad', 'Happy', 'Sad', 'Sad',\n",
       "       'Happy', 'Greetings', 'Sad', 'Happy', 'Greetings', 'Sad',\n",
       "       'Greetings', 'Greetings', 'Sad', 'Happy', 'Greetings', 'Sad',\n",
       "       'Greetings', 'Sad', 'Greetings', 'Sad'], dtype='<U9')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_models['rc'].predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Evaluate and Serialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score # Accuracy metrics \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 1.0\n",
      "rc 1.0\n",
      "rf 1.0\n",
      "gb 1.0\n"
     ]
    }
   ],
   "source": [
    "for algo, model in fit_models.items():\n",
    "    yhat = model.predict(X_test)\n",
    "    print(algo, accuracy_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sad', 'Greetings', 'Happy', 'Greetings', 'Greetings', 'Greetings',\n",
       "       'Greetings', 'Happy', 'Greetings', 'Greetings', 'Sad', 'Sad',\n",
       "       'Happy', 'Greetings', 'Greetings', 'Happy', 'Greetings', 'Sad',\n",
       "       'Greetings', 'Greetings', 'Greetings', 'Happy', 'Sad', 'Sad',\n",
       "       'Happy', 'Greetings', 'Sad', 'Sad', 'Sad', 'Greetings', 'Happy',\n",
       "       'Sad', 'Greetings', 'Happy', 'Happy', 'Sad', 'Greetings', 'Happy',\n",
       "       'Greetings', 'Sad', 'Sad', 'Sad', 'Sad', 'Greetings', 'Sad',\n",
       "       'Greetings', 'Happy', 'Sad', 'Happy', 'Happy', 'Happy', 'Sad',\n",
       "       'Happy', 'Sad', 'Greetings', 'Happy', 'Greetings', 'Happy',\n",
       "       'Happy', 'Sad', 'Happy', 'Sad', 'Happy', 'Sad', 'Sad', 'Greetings',\n",
       "       'Sad', 'Greetings', 'Greetings', 'Sad', 'Happy', 'Happy', 'Sad',\n",
       "       'Greetings', 'Sad', 'Happy', 'Sad', 'Greetings', 'Happy',\n",
       "       'Greetings', 'Happy', 'Happy', 'Happy', 'Sad', 'Greetings', 'Sad',\n",
       "       'Sad', 'Greetings', 'Greetings', 'Happy', 'Sad', 'Greetings',\n",
       "       'Sad', 'Sad', 'Sad', 'Sad', 'Sad', 'Sad', 'Happy', 'Sad', 'Happy',\n",
       "       'Greetings', 'Greetings', 'Happy', 'Greetings', 'Greetings',\n",
       "       'Greetings', 'Greetings', 'Happy', 'Sad', 'Happy', 'Sad', 'Sad',\n",
       "       'Happy', 'Greetings', 'Sad', 'Happy', 'Greetings', 'Sad',\n",
       "       'Greetings', 'Greetings', 'Sad', 'Happy', 'Greetings', 'Sad',\n",
       "       'Greetings', 'Sad', 'Greetings', 'Sad'], dtype=object)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_models['rf'].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7            Sad\n",
       "412    Greetings\n",
       "254        Happy\n",
       "308    Greetings\n",
       "289    Greetings\n",
       "         ...    \n",
       "90           Sad\n",
       "400    Greetings\n",
       "54           Sad\n",
       "323    Greetings\n",
       "148          Sad\n",
       "Name: class, Length: 129, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('body_language.pkl', 'wb') as f:\n",
    "    pickle.dump(fit_models['rf'], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "4. Make Detections with Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('body_language.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;randomforestclassifier&#x27;, RandomForestClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;randomforestclassifier&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('randomforestclassifier', RandomForestClassifier())])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False        \n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "        # print(results.face_landmarks)\n",
    "        \n",
    "        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True   \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # 1. Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                                 )\n",
    "        \n",
    "        # 2. Right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 3. Left Hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 4. Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        # Export coordinates\n",
    "        try:\n",
    "            # Extract Pose landmarks\n",
    "            pose = results.pose_landmarks.landmark\n",
    "            pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "            \n",
    "            # Extract Face landmarks\n",
    "            face = results.face_landmarks.landmark\n",
    "            face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n",
    "            \n",
    "            # Concate rows\n",
    "            row = pose_row+face_row\n",
    "\n",
    "\n",
    "            # Make Detections\n",
    "            X = pd.DataFrame([row])\n",
    "            body_language_class = model.predict(X)[0]\n",
    "            body_language_prob = model.predict_proba(X)[0]\n",
    "            print(body_language_class, body_language_prob)\n",
    "            \n",
    "            # Grab ear coords\n",
    "            coords = tuple(np.multiply(\n",
    "                            np.array(\n",
    "                                (results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].x, \n",
    "                                 results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].y))\n",
    "                        , [640,480]).astype(int))\n",
    "            \n",
    "            cv2.rectangle(image, \n",
    "                          (coords[0], coords[1]+5), \n",
    "                          (coords[0]+len(body_language_class)*20, coords[1]-30), \n",
    "                          (245, 117, 16), -1)\n",
    "            cv2.putText(image, body_language_class, coords, \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Get status box\n",
    "            cv2.rectangle(image, (0,0), (250, 60), (245, 117, 16), -1)\n",
    "            \n",
    "            # Display Class\n",
    "            cv2.putText(image, 'CLASS'\n",
    "                        , (95,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, body_language_class.split(' ')[0]\n",
    "                        , (90,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Display Probability\n",
    "            cv2.putText(image, 'PROB'\n",
    "                        , (15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, str(round(body_language_prob[np.argmax(body_language_prob)],2))\n",
    "                        , (10,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "                        \n",
    "        cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(373, 150)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(np.multiply(np.array((results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].x, \n",
    "results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].y)), [640,480]).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Git steps to push code form beginning\n",
    "\n",
    "git init\n",
    "git add file\n",
    "git commit -m \"first commit\"\n",
    "git remote add origin \"http....\"\n",
    "git push -u origin master\n",
    "\n",
    "# Git steps to push code in new branch collaborating with team\n",
    "git pull\n",
    "git status\n",
    "git checkout -b \"name of branch\"\n",
    "git config --global user.email farah.abdelli@esprit.tn\n",
    "git config --global user.name farahabdelli\n",
    "git commit \"commit\"\n",
    "git push -u origin \"branch name\"\n",
    "\n",
    "\n",
    "#commands\n",
    "python -m pip install 'package'\n",
    "python -m pip install --upgrade pip\n",
    "streamlit run datavis.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "022a9a6482eaf02d50898206bfe85d505610851c09ba0130f14d4758edb773a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
